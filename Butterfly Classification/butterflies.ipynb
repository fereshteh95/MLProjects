{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      " - 79s - loss: 0.9858 - val_loss: 0.6911\n",
      "Epoch 2/5\n",
      " - 94s - loss: 0.6823 - val_loss: 0.6843\n",
      "Epoch 3/5\n",
      " - 97s - loss: 0.6767 - val_loss: 0.6838\n",
      "Epoch 4/5\n",
      " - 83s - loss: 0.6586 - val_loss: 0.6904\n",
      "Epoch 5/5\n",
      " - 86s - loss: 0.6391 - val_loss: 0.7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x210b3c97b08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten, Input\n",
    "from keras import optimizers, losses\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def list_images(path, class_label):\n",
    "    images = []\n",
    "    for image_path in os.listdir(path):\n",
    "        new_path = os.path.join(path, image_path)\n",
    "        img = cv.imread(new_path)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        images.append([img, class_label])\n",
    "    return images\n",
    "\n",
    "train_class1 = \"butterflies/train/maniola_jurtina\"\n",
    "train_class2 = \"butterflies/train/pyronia_tithonus\"\n",
    "\n",
    "val_class1 = \"butterflies/valid/maniola_jurtina\"\n",
    "val_class2 = \"butterflies/valid/pyronia_tithonus\"\n",
    "\n",
    "train_c1 = np.array(list_images(train_class1, 0))\n",
    "train_c2 = np.array(list_images(train_class2, 1))\n",
    "val_c1 = np.array(list_images(val_class1, 0))\n",
    "val_c2 = np.array(list_images(val_class2, 1))\n",
    "\n",
    "train_data = np.concatenate([train_c1, train_c2], axis=0)\n",
    "val_data = np.concatenate([val_c1, val_c2], axis=0)\n",
    "\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(val_data)\n",
    "\n",
    "X_train = train_data[:, 0]\n",
    "y_train = train_data[:, 1]\n",
    "X_val = val_data[:, 0]\n",
    "y_val = val_data[:, 1]\n",
    "x_train = []\n",
    "for i in range(len(X_train)):\n",
    "    x_train.append(X_train[i])\n",
    "\n",
    "x_val = []\n",
    "for i in range(len(X_val)):\n",
    "    x_val.append(X_val[i])\n",
    "\n",
    "X_val = np.array(x_val)\n",
    "X_train = np.array(x_train)\n",
    "X_train = X_train/255\n",
    "X_train = X_train.reshape(1800, 75, 75, 1)\n",
    "X_val = X_val/255\n",
    "X_val = X_val.reshape(600, 75, 75, 1)\n",
    "y_val = pd.get_dummies(y_val.astype(str))\n",
    "y_train = pd.get_dummies(y_train.astype(str))\n",
    "X_test = X_val[0:100][:]\n",
    "y_test = y_val[0:100][:]\n",
    "X_val = X_val[100:][:]\n",
    "y_val = y_val[100:][:]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add Model Layers\n",
    "model.add(Conv2D(64, kernel_size=3, padding='SAME',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias='True',\n",
    "                 activation='relu',\n",
    "                 input_shape=(75, 75, 1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='SAME'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, padding='SAME',\n",
    "                 data_format='channels_last',\n",
    "                 use_bias='True',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='SAME'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "adam = optimizers.adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X_test)\n",
    "y_pred = np.zeros((100, 1))\n",
    "y_act = np.zeros((100, 1))\n",
    "y_test = y_test.values\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = list(predicted_y[i][:]).index(predicted_y[i][:].max())\n",
    "    y_act[i] = list(y_test[i][:]).index(y_test[i][:].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i][0] == y_test[i][0]:\n",
    "        acc += 1\n",
    "\n",
    "test_acc = acc/len(y_pred)\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
